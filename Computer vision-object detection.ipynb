{
  "metadata" : {
    "kernelspec" : {
      "display_name" : "Python 2",
      "language" : "python",
      "name" : "python2"
    },
    "language_info" : {
      "file_extension" : ".py",
      "mimetype" : "text/x-python",
      "name" : "python"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 2,
  "cells" : [ {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "import mxnet as mx\nfrom mxnet import nd\nfrom mxnet.contrib.ndarray import MultiBoxPrior\n\nn = 40\n# shape: batch x channel x height x weight\nx = nd.random_uniform(shape=(1, 3, n, n))\n\ny = MultiBoxPrior(x, sizes=[.5, .25, .1], ratios=[1, 2, .5])\n\n# the first anchor box generated for pixel at (20,20)\n# its format is (x_min, y_min, x_max, y_max)\nboxes = y.reshape((n, n, -1, 4))\nprint('The first anchor box at row 21, column 21:', boxes[20, 20, 0, :])" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "import matplotlib.pyplot as plt\ndef box_to_rect(box, color, linewidth=3):\n    \"\"\"convert an anchor box to a matplotlib rectangle\"\"\"\n    box = box.asnumpy()\n    return plt.Rectangle(\n        (box[0], box[1]), (box[2]-box[0]), (box[3]-box[1]),\n        fill=False, edgecolor=color, linewidth=linewidth)\ncolors = ['blue', 'green', 'red', 'black', 'magenta']\nplt.imshow(nd.ones((n, n, 3)).asnumpy())\nanchors = boxes[20, 20, :, :]\nfor i in range(anchors.shape[0]):\n    plt.gca().add_patch(box_to_rect(anchors[i,:]*n, colors[i]))\nplt.show()" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from mxnet.gluon import nn\ndef class_predictor(num_anchors, num_classes):\n    \"\"\"return a layer to predict classes\"\"\"\n    return nn.Conv2D(num_anchors * (num_classes + 1), 3, padding=1)\n\ncls_pred = class_predictor(5, 10)\ncls_pred.initialize()\nx = nd.zeros((2, 3, 20, 20))\nprint('Class prediction', cls_pred(x).shape)\n" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def box_predictor(num_anchors):\n    \"\"\"return a layer to predict delta locations\"\"\"\n    return nn.Conv2D(num_anchors * 4, 3, padding=1)\n\nbox_pred = box_predictor(10)\nbox_pred.initialize()\nx = nd.zeros((2, 3, 20, 20))\nprint('Box prediction', box_pred(x).shape)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def down_sample(num_filters):\n    \"\"\"stack two Conv-BatchNorm-Relu blocks and then a pooling layer\n    to halve the feature size\"\"\"\n    out = nn.HybridSequential()\n    for _ in range(2):\n        out.add(nn.Conv2D(num_filters, 3, strides=1, padding=1))\n        out.add(nn.BatchNorm(in_channels=num_filters))\n        out.add(nn.Activation('relu'))\n    out.add(nn.MaxPool2D(2))\n    return out\n\nblk = down_sample(10)\nblk.initialize()\nx = nd.zeros((2, 3, 20, 20))\nprint('Before', x.shape, 'after', blk(x).shape)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "# a certain feature map with 20x20 spatial shape\nfeat1 = nd.zeros((2, 8, 20, 20))\nprint('Feature map 1', feat1.shape)\ncls_pred1 = class_predictor(5, 10)\ncls_pred1.initialize()\ny1 = cls_pred1(feat1)\nprint('Class prediction for feature map 1', y1.shape)\n# down-sample\nds = down_sample(16)\nds.initialize()\nfeat2 = ds(feat1)\nprint('Feature map 2', feat2.shape)\ncls_pred2 = class_predictor(3, 10)\ncls_pred2.initialize()\ny2 = cls_pred2(feat2)\nprint('Class prediction for feature map 2', y2.shape)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def flatten_prediction(pred):\n    return nd.flatten(nd.transpose(pred, axes=(0, 2, 3, 1)))\n\ndef concat_predictions(preds):\n    return nd.concat(*preds, dim=1)\n\nflat_y1 = flatten_prediction(y1)\nprint('Flatten class prediction 1', flat_y1.shape)\nflat_y2 = flatten_prediction(y2)\nprint('Flatten class prediction 2', flat_y2.shape)\nprint('Concat class predictions', concat_predictions([flat_y1, flat_y2]).shape)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from mxnet import gluon\ndef body():\n    \"\"\"return the body network\"\"\"\n    out = nn.HybridSequential()\n    for nfilters in [16, 32, 64]:\n        out.add(down_sample(nfilters))\n    return out\n\nbnet = body()\nbnet.initialize()\nx = nd.zeros((2, 3, 256, 256))\nprint('Body network', [y.shape for y in bnet(x)])" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def toy_ssd_model(num_anchors, num_classes):\n    \"\"\"return SSD modules\"\"\"\n    downsamples = nn.Sequential()\n    class_preds = nn.Sequential()\n    box_preds = nn.Sequential()\n\n    downsamples.add(down_sample(128))\n    downsamples.add(down_sample(128))\n    downsamples.add(down_sample(128))\n\n    for scale in range(5):\n        class_preds.add(class_predictor(num_anchors, num_classes))\n        box_preds.add(box_predictor(num_anchors))\n\n    return body(), downsamples, class_preds, box_preds\n\nprint(toy_ssd_model(5, 2))" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def toy_ssd_forward(x, body, downsamples, class_preds, box_preds, sizes, ratios):\n    # extract feature with the body network\n    x = body(x)\n\n    # for each scale, add anchors, box and class predictions,\n    # then compute the input to next scale\n    default_anchors = []\n    predicted_boxes = []\n    predicted_classes = []\n\n    for i in range(5):\n        default_anchors.append(MultiBoxPrior(x, sizes=sizes[i], ratios=ratios[i]))\n        predicted_boxes.append(flatten_prediction(box_preds[i](x)))\n        predicted_classes.append(flatten_prediction(class_preds[i](x)))\n        if i < 3:\n            x = downsamples[i](x)\n        elif i == 3:\n            # simply use the pooling layer\n            x = nd.Pooling(x, global_pool=True, pool_type='max', kernel=(4, 4))\n\n    return default_anchors, predicted_classes, predicted_boxes" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from mxnet import gluon\nclass ToySSD(gluon.Block):\n    def __init__(self, num_classes, **kwargs):\n        super(ToySSD, self).__init__(**kwargs)\n        # anchor box sizes for 4 feature scales\n        self.anchor_sizes = [[.2, .272], [.37, .447], [.54, .619], [.71, .79], [.88, .961]]\n        # anchor box ratios for 4 feature scales\n        self.anchor_ratios = [[1, 2, .5]] * 5\n        self.num_classes = num_classes\n\n        with self.name_scope():\n            self.body, self.downsamples, self.class_preds, self.box_preds = toy_ssd_model(4, num_classes)\n\n    def forward(self, x):\n        default_anchors, predicted_classes, predicted_boxes = toy_ssd_forward(x, self.body, self.downsamples,\n            self.class_preds, self.box_preds, self.anchor_sizes, self.anchor_ratios)\n        # we want to concatenate anchors, class predictions, box predictions from different layers\n        anchors = concat_predictions(default_anchors)\n        box_preds = concat_predictions(predicted_boxes)\n        class_preds = concat_predictions(predicted_classes)\n        # it is better to have class predictions reshaped for softmax computation\n        class_preds = nd.reshape(class_preds, shape=(0, -1, self.num_classes + 1))\n\n        return anchors, class_preds, box_preds\n" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "# instantiate a ToySSD network with 10 classes\nnet = ToySSD(2)\nnet.initialize()\nx = nd.zeros((1, 3, 256, 256))\ndefault_anchors, class_predictions, box_predictions = net(x)\nprint('Outputs:', 'anchors', default_anchors.shape, 'class prediction', class_predictions.shape, 'box prediction', box_predictions.shape)\n" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from mxnet.test_utils import download\nimport os.path as osp\ndef verified(file_path, sha1hash):\n    import hashlib\n    sha1 = hashlib.sha1()\n    with open(file_path, 'rb') as f:\n        while True:\n            data = f.read(1048576)\n            if not data:\n                break\n            sha1.update(data)\n    matched = sha1.hexdigest() == sha1hash\n    if not matched:\n        print('Found hash mismatch in file {}, possibly due to incomplete download.'.format(file_path))\n    return matched\n\nurl_format = 'https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/pikachu/{}'\nhashes = {'train.rec': 'e6bcb6ffba1ac04ff8a9b1115e650af56ee969c8',\n          'train.idx': 'dcf7318b2602c06428b9988470c731621716c393',\n          'val.rec': 'd6c33f799b4d058e82f2cb5bd9a976f69d72d520'}\nfor k, v in hashes.items():\n    fname = 'pikachu_' + k\n    target = osp.join('data', fname)\n    print target\n    url = url_format.format(k)\n    if not osp.exists(target) or not verified(target, v):\n        print('Downloading', target, url)\n        download(url, fname=fname, dirname='/tmp/data', overwrite=True)\n" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "import mxnet.image as image\ndata_shape = 256\nbatch_size = 32\ndef get_iterators(data_shape, batch_size):\n    class_names = ['pikachu']\n    num_class = len(class_names)\n    train_iter = image.ImageDetIter(\n        batch_size=batch_size,\n        data_shape=(3, data_shape, data_shape),\n        path_imgrec='/tmp/data/pikachu_train.rec',\n        path_imgidx='/tmp/data/pikachu_train.idx',\n        shuffle=True,\n        mean=True,\n        rand_crop=1,\n        min_object_covered=0.95,\n        max_attempts=200)\n    val_iter = image.ImageDetIter(\n        batch_size=batch_size,\n        data_shape=(3, data_shape, data_shape),\n        path_imgrec='/tmp/data/pikachu_val.rec',\n        shuffle=False,\n        mean=True)\n    return train_iter, val_iter, class_names, num_class\n\ntrain_data, test_data, class_names, num_class = get_iterators(data_shape, batch_size)\nbatch = train_data.next()\nprint(batch)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "import numpy as np\n\nimg = batch.data[0][0].asnumpy()  # grab the first image, convert to numpy array\nimg = img.transpose((1, 2, 0))  # we want channel to be the last dimension\nimg += np.array([123, 117, 104])\nimg = img.astype(np.uint8)  # use uint8 (0-255)\n# draw bounding boxes on image\nfor label in batch.label[0][0].asnumpy():\n    if label[0] < 0:\n        break\n    print(label)\n    xmin, ymin, xmax, ymax = [int(x * data_shape) for x in label[1:5]]\n    rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor=(1, 0, 0), linewidth=3)\n    plt.gca().add_patch(rect)\nplt.imshow(img)\nplt.show()" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from mxnet.contrib.ndarray import MultiBoxTarget\ndef training_targets(default_anchors, class_predicts, labels):\n    class_predicts = nd.transpose(class_predicts, axes=(0, 2, 1))\n    z = MultiBoxTarget(*[default_anchors, labels, class_predicts])\n    box_target = z[0]  # box offset target for (x, y, width, height)\n    box_mask = z[1]  # mask is used to ignore box offsets we don't want to penalize, e.g. negative samples\n    cls_target = z[2]  # cls_target is an array of labels for all anchors boxes\n    return box_target, box_mask, cls_target" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "class FocalLoss(gluon.loss.Loss):\n    def __init__(self, axis=-1, alpha=0.25, gamma=2, batch_axis=0, **kwargs):\n        super(FocalLoss, self).__init__(None, batch_axis, **kwargs)\n        self._axis = axis\n        self._alpha = alpha\n        self._gamma = gamma\n\n    def hybrid_forward(self, F, output, label):\n        output = F.softmax(output)\n        pt = F.pick(output, label, axis=self._axis, keepdims=True)\n        loss = -self._alpha * ((1 - pt) ** self._gamma) * F.log(pt)\n        return F.mean(loss, axis=self._batch_axis, exclude=True)\n\n# cls_loss = gluon.loss.SoftmaxCrossEntropyLoss()\ncls_loss = FocalLoss()\nprint(cls_loss)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "class SmoothL1Loss(gluon.loss.Loss):\n    def __init__(self, batch_axis=0, **kwargs):\n        super(SmoothL1Loss, self).__init__(None, batch_axis, **kwargs)\n\n    def hybrid_forward(self, F, output, label, mask):\n        loss = F.smooth_l1((output - label) * mask, scalar=1.0)\n        return F.mean(loss, self._batch_axis, exclude=True)\n\nbox_loss = SmoothL1Loss()\nprint(box_loss)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "cls_metric = mx.metric.Accuracy()\nbox_metric = mx.metric.MAE()  # measure absolute difference between prediction and target" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "### Set context for training\nctx = mx.cpu()  # it may takes too long to train using CPU\ntry:\n    _ = nd.zeros(1, ctx=ctx)\n    # pad label for cuda implementation\n    train_data.reshape(label_shape=(3, 5))\n    train_data = test_data.sync_label_shape(train_data)\nexcept mx.base.MXNetError as err:\n    print('No GPU enabled, fall back to CPU, sit back and be patient...')\n    ctx = mx.cpu()" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "net = ToySSD(num_class)\nnet.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "net.collect_params().reset_ctx(ctx)\ntrainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1, 'wd': 5e-4})" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "epochs = 150  # set larger to get better performance\nlog_interval = 20\nfrom_scratch = False  # set to True to train from scratch\nif from_scratch:\n    start_epoch = 0\nelse:\n    start_epoch = 148\n    pretrained = '/tmp/ssd_pretrained.params'\n    sha1 = 'fbb7d872d76355fff1790d864c2238decdb452bc'\n    url = 'https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/models/ssd_pikachu-fbb7d872.params'\n    if not osp.exists(pretrained) or not verified(pretrained, sha1):\n        print('Downloading', pretrained, url)\n        download(url, fname=pretrained, overwrite=True)\n    net.load_params(pretrained, ctx)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "import time\nfrom mxnet import autograd as ag\nfor epoch in range(start_epoch, epochs):\n    # reset iterator and tick\n    train_data.reset()\n    cls_metric.reset()\n    box_metric.reset()\n    tic = time.time()\n    # iterate through all batch\n    for i, batch in enumerate(train_data):\n        btic = time.time()\n        # record gradients\n        with ag.record():\n            x = batch.data[0].as_in_context(ctx)\n            y = batch.label[0].as_in_context(ctx)\n            default_anchors, class_predictions, box_predictions = net(x)\n            box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, y)\n            # losses\n            loss1 = cls_loss(class_predictions, cls_target)\n            loss2 = box_loss(box_predictions, box_target, box_mask)\n            # sum all losses\n            loss = loss1 + loss2\n            # backpropagate\n            loss.backward()\n        # apply \n        trainer.step(batch_size)\n        # update metrics\n        cls_metric.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n        box_metric.update([box_target], [box_predictions * box_mask])\n        if (i + 1) % log_interval == 0:\n            name1, val1 = cls_metric.get()\n            name2, val2 = box_metric.get()\n            print('[Epoch %d Batch %d] speed: %f samples/s, training: %s=%f, %s=%f' \n                  %(epoch ,i, batch_size/(time.time()-btic), name1, val1, name2, val2))\n    \n    # end of epoch logging\n    name1, val1 = cls_metric.get()\n    name2, val2 = box_metric.get()\n    print('[Epoch %d] training: %s=%f, %s=%f'%(epoch, name1, val1, name2, val2))\n    print('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))\n\n# we can save the trained parameters to disk\nnet.save_params('/tmp/ssd_%d.params' % epochs)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "import numpy as np\nimport cv2\ndef preprocess(image):\n    \"\"\"Takes an image and apply preprocess\"\"\"\n    # resize to data_shape\n    image = cv2.resize(image, (data_shape, data_shape))\n    # swap BGR to RGB\n    image = image[:, :, (2, 1, 0)]\n    # convert to float before subtracting mean\n    image = image.astype(np.float32)\n    # subtract mean\n    image -= np.array([123, 117, 104])\n    # organize as [batch-channel-height-width]\n    image = np.transpose(image, (2, 0, 1))\n    image = image[np.newaxis, :]\n    # convert to ndarray\n    image = nd.array(image)\n    return image\n\nimage = cv2.imread('/tmp/eider-user/userfile/sssareen/pikachu.jpg')\nx = preprocess(image)\nprint('x', x.shape)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "# if pre-trained model is provided, we can load it\n# net.load_params('ssd_%d.params' % epochs, ctx)\nanchors, cls_preds, box_preds = net(x.as_in_context(ctx))\nprint('anchors', anchors)\nprint('class predictions', cls_preds)\nprint('box delta predictions', box_preds)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "from mxnet.contrib.ndarray import MultiBoxDetection\n# convert predictions to probabilities using softmax\ncls_probs = nd.SoftmaxActivation(nd.transpose(cls_preds, (0, 2, 1)), mode='channel')\n# apply shifts to anchors boxes, non-maximum-suppression, etc...\noutput = MultiBoxDetection(*[cls_probs, box_preds, anchors], force_suppress=True, clip=False)\nprint(output)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "def display(img, out, thresh=0.5):\n    import random\n    import matplotlib as mpl\n    mpl.rcParams['figure.figsize'] = (10,10)\n    pens = dict()\n    plt.clf()\n    plt.imshow(img)\n    for det in out:\n        cid = int(det[0])\n        if cid < 0:\n            continue\n        score = det[1]\n        if score < thresh:\n            continue\n        if cid not in pens:\n            pens[cid] = (random.random(), random.random(), random.random())\n        scales = [img.shape[1], img.shape[0]] * 2\n        xmin, ymin, xmax, ymax = [int(p * s) for p, s in zip(det[2:6].tolist(), scales)]\n        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n                             edgecolor=pens[cid], linewidth=3)\n        plt.gca().add_patch(rect)\n        text = class_names[cid]\n        plt.gca().text(xmin, ymin-2, '{:s} {:.3f}'.format(text, score),\n                       bbox=dict(facecolor=pens[cid], alpha=0.5),\n                       fontsize=12, color='white')\n    plt.show()\n\ndisplay(image[:, :, (2, 1, 0)], output[0].asnumpy(), thresh=0.45)" ]
  }, {
    "cell_type" : "code",
    "execution_count" : 0,
    "outputs" : [ ],
    "metadata" : { },
    "source" : [ "" ]
  } ]
}